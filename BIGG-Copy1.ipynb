{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab74ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing matplotlib failed. Plotting will not work.\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'prophet' from 'fbprophet' (C:\\Users\\DBRCI18\\Anaconda4\\envs\\Python3\\lib\\site-packages\\fbprophet\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24144/3451983631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprophet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'prophet' from 'fbprophet' (C:\\Users\\DBRCI18\\Anaconda4\\envs\\Python3\\lib\\site-packages\\fbprophet\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from fbprophet import prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa916a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import random\n",
    "import holidays\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmdarima as pm\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from fbprophet import Prophet\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "def test_stationarity_acf_pacf(data, sample, max_lag):\n",
    "    \"\"\"\n",
    "    This function tests the stationarity and plot the autocorrelation\n",
    "    and partial autocorrelation of the time series.\n",
    "    Test stationarity by:\n",
    "    - running Augmented Dickey-Fuller test with 95%\n",
    "    In statistics, the Dickey–Fuller test tests the null hypothesis\n",
    "    that a unit root is present in an autoregressive model.\n",
    "    The alternative hypothesis is different depending\n",
    "    on which version of the test is used,\n",
    "    but is usually stationarity or trend-stationarity.\n",
    "    - plotting mean and variance of a sample from data\n",
    "    - plotting autocorrelation and partial autocorrelation\n",
    "\n",
    "    p-value > 0.05: Fail to reject the null hypothesis (H0),\n",
    "    the data has a unit root and is non-stationary.\n",
    "    p-value <= 0.05: Reject the null hypothesis (H0),\n",
    "    the data does not have a unit root and is stationary.\n",
    "    This function is used to verify stationarity\n",
    "    so that suitable forecasting methods can be applied.\n",
    "\n",
    "    Partial autocorrelation is a summary of the relationship\n",
    "    between an observation in a time series with observations\n",
    "    at prior time steps with the relationships of intervening\n",
    "    observations removed. The partial autocorrelation at lag k\n",
    "    is the correlation that results after removing the effect\n",
    "    of any correlations due to the terms at shorter lags.\n",
    "\n",
    "    The autocorrelation for an observation and an observation\n",
    "    at a prior time step comprises both the direct correlation\n",
    "    and indirect correlations. These indirect correlations are\n",
    "    a linear function of the correlation of the observation,\n",
    "    with observations at intervening time steps.\n",
    "\n",
    "    These correlations are used to define the parameters\n",
    "    of the forecasting methods (lag).\n",
    "\n",
    "    :parameter\n",
    "     :param data: timeSeries for which the stationarity as to be evaluated.\n",
    "     :param sample: Sample (float) of the data that will be evaluated.\n",
    "     :param max_lag: Maximum number of lag which included in test.\n",
    "                    The default value is 12*(nobs/100)^{1/4}.\n",
    "    :return:\n",
    "      plot of the mean and variance of the sample with the p-value\n",
    "      and plot of the autocorrelation and partial autocorrelation.\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        raise ValueError(\"Input series must not be empty.\")\n",
    "\n",
    "    elif 0.0 > sample or sample > 1.0:\n",
    "        raise ValueError(\"Sample value should be between 0 and 1\")\n",
    "\n",
    "    ts_ax = plt.subplot2grid(shape=(2, 2), loc=(0, 0), colspan=2)\n",
    "    pacf_ax = plt.subplot2grid(shape=(2, 2), loc=(1, 0))\n",
    "    acf_ax = plt.subplot2grid(shape=(2, 2), loc=(1, 1))\n",
    "    dtf_ts = data.to_frame(name=\"ts\")\n",
    "    sample_size = int(len(data) * sample)\n",
    "    dtf_ts[\"mean\"] = dtf_ts[\"ts\"].head(sample_size).mean()\n",
    "    dtf_ts[\"lower\"] = dtf_ts[\"ts\"].head(sample_size).mean() + dtf_ts[\"ts\"].head(sample_size).std()\n",
    "    dtf_ts[\"upper\"] = dtf_ts[\"ts\"].head(sample_size).mean() - dtf_ts[\"ts\"].head(sample_size).std()\n",
    "    dtf_ts[\"ts\"].plot(ax=ts_ax, color=\"black\", legend=False)\n",
    "    dtf_ts[\"mean\"].plot(\n",
    "        ax=ts_ax, legend=False, color=\"red\",\n",
    "        linestyle=\"--\", linewidth=0.7)\n",
    "    ts_ax.fill_between(\n",
    "        x=dtf_ts.index, y1=dtf_ts['lower'],\n",
    "        y2=dtf_ts['upper'], color='lightskyblue', alpha=0.4)\n",
    "    dtf_ts[\"mean\"].head(sample_size).plot(\n",
    "        ax=ts_ax, legend=False,\n",
    "        color=\"red\", linewidth=0.9)\n",
    "    ts_ax.fill_between(\n",
    "        x=dtf_ts.index, y1=dtf_ts['lower'],\n",
    "        y2=dtf_ts['upper'], color='lightskyblue', alpha=0.4)\n",
    "    dtf_ts[\"mean\"].head(sample_size).plot(\n",
    "        ax=ts_ax, legend=False,\n",
    "        color=\"red\", linewidth=0.9)\n",
    "    ts_ax.fill_between(\n",
    "        x=dtf_ts.head(sample_size).index,\n",
    "        y1=dtf_ts['lower'].head(sample_size),\n",
    "        y2=dtf_ts['upper'].head(sample_size), color='lightskyblue')\n",
    "    adfuller_test = sm.tsa.stattools.adfuller(\n",
    "        data, maxlag=max_lag, autolag=\"AIC\")\n",
    "    adf, p, critical_value = adfuller_test[0], adfuller_test[1], adfuller_test[4][\"5%\"]\n",
    "    p = round(p, 3)\n",
    "    conclusion = \"Stationary\" if p < 0.05 else \"Non-Stationary\"\n",
    "    ts_ax.set_title(\n",
    "        'Dickey-Fuller Test 95%: ' + conclusion +\n",
    "        '(p value: ' + str(p) + ')')\n",
    "\n",
    "    # pacf (for AR) and acf (for MA)\n",
    "    smt.graphics.plot_pacf(\n",
    "        data, lags=30, ax=pacf_ax,\n",
    "        title=\"Partial Autocorrelation (for AR component)\")\n",
    "    smt.graphics.plot_acf(\n",
    "        data, lags=30, ax=acf_ax,\n",
    "        title=\"Autocorrelation (for MA component)\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def split_train_test(data, test, plot):\n",
    "    \"\"\"\n",
    "    Split train/test from any given data point.\n",
    "    :parameter\n",
    "      :param data: pandas Series\n",
    "      :param test: num or str - test size    or index position\n",
    "                   (ex. \"yyyy-mm-dd\", 1000)\n",
    "      :param plot: bool to decide if the 2 new time series have to be plotted\n",
    "    :return\n",
    "      ts_train, ts_test\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        raise ValueError(\"Input series must be not empty.\")\n",
    "\n",
    "    # define splitting point\n",
    "    if type(test) is float:\n",
    "        split = int(len(data) * (1 - test))\n",
    "        perc = test\n",
    "    elif type(test) is str:\n",
    "        split = data.reset_index()[\n",
    "            data.reset_index().iloc[:, 0] == test].index[0]\n",
    "        perc = round(len(data[split:]) / len(data), 2)\n",
    "    else:\n",
    "        split = test\n",
    "        perc = round(len(data[split:]) / len(data), 2)\n",
    "    print(\n",
    "        \"--- splitting at index: \", split, \"|\",\n",
    "        data.index[split], \"| test size:\", perc, \" ---\")\n",
    "\n",
    "    # split data\n",
    "    ts_train = data.head(split)\n",
    "    ts_test = data.tail(len(data) - split)\n",
    "    if plot is True:\n",
    "        fig, ax = plt.subplots(\n",
    "            nrows=1, ncols=2,\n",
    "            sharey=True, figsize=(15, 5))\n",
    "        ts_train.plot(\n",
    "            ax=ax[0], grid=True,\n",
    "            title=\"Train\",\n",
    "            color=\"black\")\n",
    "        ts_test.plot(\n",
    "            ax=ax[1], grid=True,\n",
    "            title=\"Test\",\n",
    "            color=\"blue\")\n",
    "        ax[0].set(xlabel=None)\n",
    "        ax[1].set(xlabel=None)\n",
    "        plt.show()\n",
    "\n",
    "    return ts_train, ts_test\n",
    "\n",
    "\n",
    "def evaluate_forecast(dtf, title, plot=True):\n",
    "    \"\"\"\n",
    "    Evaluation metrics for predictions.\n",
    "\n",
    "    :parameter\n",
    "      :param dtf: DataFrame with columns raw values, fitted training\n",
    "                   values, predicted test values.\n",
    "      :param title: Title of the plot\n",
    "      :param plot:  Bool to visualize on a plot. Default is True.\n",
    "\n",
    "    :return:\n",
    "      DataFrame with raw ts and forecast.\n",
    "    \"\"\"\n",
    "    if dtf.empty:\n",
    "        raise ValueError(\"Input series must be not empty.\")\n",
    "\n",
    "    try:\n",
    "        # residuals\n",
    "        dtf[\"residuals\"] = dtf[\"ts\"] - dtf[\"model\"]\n",
    "        dtf[\"error\"] = dtf[\"ts\"] - dtf[\"forecast\"]\n",
    "        dtf[\"error_pct\"] = dtf[\"error\"] / dtf[\"ts\"]\n",
    "\n",
    "        # kpi\n",
    "        residuals_mean = dtf[\"residuals\"].mean()\n",
    "        residuals_std = dtf[\"residuals\"].std()\n",
    "        error_mean = dtf[\"error\"].mean()\n",
    "        error_std = dtf[\"error\"].std()\n",
    "        mape = dtf[\"error_pct\"].apply(lambda x: np.abs(x)).mean()\n",
    "        mae = dtf[\"error\"].apply(lambda x: np.abs(x)).mean()\n",
    "        mse = dtf[\"error\"].apply(lambda x: x ** 2).mean()\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # intervals\n",
    "        dtf[\"conf_int_low\"] = dtf[\"forecast\"] - 1.96 * residuals_std\n",
    "        dtf[\"conf_int_up\"] = dtf[\"forecast\"] + 1.96 * residuals_std\n",
    "        dtf[\"pred_int_low\"] = dtf[\"forecast\"] - 1.96 * error_std\n",
    "        dtf[\"pred_int_up\"] = dtf[\"forecast\"] + 1.96 * error_std\n",
    "\n",
    "        # plot\n",
    "        if plot is True:\n",
    "            fig = plt.figure(figsize=(20, 13))\n",
    "            fig.suptitle(title, fontsize=20)\n",
    "            ax1 = fig.add_subplot(2, 2, 1)\n",
    "            ax2 = fig.add_subplot(2, 2, 2, sharey=ax1)\n",
    "            ax3 = fig.add_subplot(2, 2, 3)\n",
    "            ax4 = fig.add_subplot(2, 2, 4)\n",
    "            # training\n",
    "            dtf[pd.notnull(dtf[\"model\"])][[\"ts\", \"model\"]].plot(\n",
    "                color=[\"black\", \"green\"], title=\"Model\", grid=True, ax=ax1)\n",
    "            ax1.set(xlabel=None)\n",
    "            # test\n",
    "            dtf[pd.isnull(dtf[\"model\"])][[\"ts\", \"forecast\"]].plot(\n",
    "                color=[\"black\", \"red\"], title=\"Forecast\", grid=True, ax=ax2)\n",
    "            ax2.fill_between(\n",
    "                x=dtf.index, y1=dtf['pred_int_low'],\n",
    "                y2=dtf['pred_int_up'], color='b', alpha=0.2)\n",
    "            ax2.fill_between(\n",
    "                x=dtf.index, y1=dtf['conf_int_low'],\n",
    "                y2=dtf['conf_int_up'], color='b', alpha=0.3)\n",
    "            ax2.set(xlabel=None)\n",
    "            # residuals\n",
    "            dtf[[\"residuals\", \"error\"]].plot(\n",
    "                ax=ax3, color=[\"green\", \"red\"], title=\"Residuals\", grid=True)\n",
    "            ax3.set(xlabel=None)\n",
    "            # residuals distribution\n",
    "            dtf[[\"residuals\", \"error\"]].plot(\n",
    "                ax=ax4, color=[\"green\", \"red\"], kind='kde',\n",
    "                title=\"Residuals Distribution\", grid=True)\n",
    "            ax4.set(ylabel=None)\n",
    "            plt.show()\n",
    "            print(\"Training --> Residuals mean:\", np.round(residuals_mean),\n",
    "                  \" | std:\", np.round(residuals_std))\n",
    "            print(\n",
    "                \"Test --> Error mean:\", np.round(error_mean),\n",
    "                \" | std:\", np.round(error_std),\n",
    "                \" | mae:\", np.round(mae), \" | mape:\", np.round(mape * 100),\n",
    "                \"%| mse:\", np.round(mse), \" | rmse:\", np.round(rmse))\n",
    "\n",
    "        return dtf[[\n",
    "            \"ts\", \"model\", \"residuals\", \"conf_int_low\", \"conf_int_up\",\n",
    "            \"forecast\", \"error\", \"pred_int_low\", \"pred_int_up\"]]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"--- got error ---\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def param_tuning_sarimax(data, m, max_order, information_criterion='aic'):\n",
    "    \"\"\"\n",
    "    Automatically discover the optimal order for a SARIMAX model.\n",
    "    The function works by conducting differencing tests to determine\n",
    "    the order of differencing, d, and then fitting models within ranges\n",
    "    of defined start_p, max_p, start_q, max_q ranges.\n",
    "\n",
    "    If the seasonal optional is enabled(allowing SARIMAX over ARIMA),\n",
    "    it also seeks to identify the optimal P and Q hyperparameters\n",
    "    after conducting the Canova-Hansen\n",
    "    to determine the optimal order of seasonal differencing, D.\n",
    "\n",
    "    In order to find the best model, it optimizes for\n",
    "    a given information_criterion\n",
    "    and returns the ARIMA which minimizes the value.\n",
    "\n",
    "    :parameter\n",
    "      :param data: timeSeries used to fit the sarimax estimator.\n",
    "      :param m: refers to the number of periods in each season.\n",
    "                      For example, m is 4 for quarterly data,\n",
    "                      12 for monthly data, or 1 for annual data.\n",
    "      :param max_order: maximum value of p+q+P+Q.\n",
    "                      If p+q >= max_order, a model will not be\n",
    "                      fit with those parameters and will progress\n",
    "                      to the next combination. Default is 5.\n",
    "      :param information_criterion: used to select the best model.\n",
    "                    Possibilities are ‘aic’, ‘bic’, ‘hqic’, ‘oob’.\n",
    "                    Default is 'aic'.\n",
    "\n",
    "    :return\n",
    "      best_model: model with the optimal parameters\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        raise ValueError(\"Input series must be not empty.\")\n",
    "    elif not isinstance(m, int):\n",
    "        raise ValueError(\"m must be an integer.\")\n",
    "\n",
    "    best_model = pm.auto_arima(\n",
    "        data, exogenous=None,\n",
    "        seasonal=True, stationary=True,\n",
    "        m=m, information_criterion=information_criterion,\n",
    "        max_order=max_order, max_p=2,\n",
    "        max_d=1, max_q=2, max_P=1, max_D=1,\n",
    "        max_Q=2, error_action='ignore')\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def fit_sarimax(ts_train, order, seasonal_order, exog_train=None):\n",
    "    \"\"\"\n",
    "    Fit SARIMAX (Seasonal ARIMA with External Regressors):\n",
    "    y[t+1] = (c + a0*y[t] + a1*y[t-1] +...+ ap*y[t-p]) + (e[t] +\n",
    "                  b1*e[t-1] + b2*e[t-2] +...+ bq*e[t-q]) + (B*X[t])\n",
    "    :parameter\n",
    "    :param ts_train: pandas timeseries\n",
    "    :param order: tuple - ARIMA(p,d,q) --> p: lag order (AR), d:\n",
    "    degree of differencing (to remove trend), q: order\n",
    "                        of moving average (MA).\n",
    "    :param seasonal_order: tuple - (P,D,Q,s) --> s: number of\n",
    "                        observations per seasonal (ex. 7 for weekly\n",
    "                        seasonality with daily data, 12 for yearly\n",
    "                        seasonality with monthly data).\n",
    "    :param exog_train: pandas dataframe or numpy array.\n",
    "\n",
    "    :return\n",
    "    Model and dtf with the fitted values\n",
    "    \"\"\"\n",
    "    # train\n",
    "    if ts_train.empty:\n",
    "        raise ValueError(\"Train series must be not empty.\")\n",
    "\n",
    "    model = smt.SARIMAX(\n",
    "        ts_train, order=order, seasonal_order=seasonal_order,\n",
    "        exog=exog_train, enforce_stationarity=False,\n",
    "        enforce_invertibility=False)\n",
    "    model = model.fit()\n",
    "    dtf_train = ts_train.to_frame(name=\"ts\")\n",
    "    dtf_train[\"model\"] = model.fittedvalues\n",
    "\n",
    "    return dtf_train, model\n",
    "\n",
    "\n",
    "def test_sarimax(ts_train, ts_test, exog_test, p, model):\n",
    "    \"\"\"\n",
    "    The function uses the model from the fit_sarimax function\n",
    "    to make predictions for the future value.\n",
    "\n",
    "    :parameter\n",
    "      :param ts_train: timeSeries used to train the model.\n",
    "      :param ts_test: timeSeries used to test the model.\n",
    "      :param exog_test: timeSeries containing the exogeneous variables.\n",
    "      :param p: number of periods to be forcasted.\n",
    "      :param model: model from the fit_sarimax function.\n",
    "\n",
    "    :return\n",
    "      Dataframe containing the true values and the forecasted ones.\n",
    "    \"\"\"\n",
    "\n",
    "    if ts_train.empty:\n",
    "        raise ValueError(\"Train series must be not empty.\")\n",
    "    elif ts_test.empty:\n",
    "        raise ValueError(\"Test series must be not empty.\")\n",
    "    elif not isinstance(p, int):\n",
    "        raise ValueError(\"p must be an integer.\")\n",
    "\n",
    "    dtf_test = ts_test[:p].to_frame(name=\"ts\")\n",
    "\n",
    "    if exog_test is None:\n",
    "        dtf_test[\"forecast\"] = model.predict(\n",
    "            start=len(ts_train) + 1,\n",
    "            end=len(ts_train) + len(ts_test[:p - 1]),\n",
    "            exog=exog_test)\n",
    "    else:\n",
    "        dtf_test[\"forecast\"] = model.predict(\n",
    "            start=len(ts_train) + 1,\n",
    "            end=len(ts_train) + len(ts_test[:p - 1]),\n",
    "            exog=exog_test[:p])\n",
    "    dtf_test = dtf_test.round()\n",
    "    return dtf_test\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "def input_prophet(ts_train, ts_test):\n",
    "    \"\"\"\n",
    "\n",
    "    The input to Prophet is always a dataframe with two columns: ds and y.\n",
    "    The ds (datestamp) column should be of a format expected by Pandas,\n",
    "    ideally YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp.\n",
    "    The function rename and adapt the format of ds.\n",
    "\n",
    "    :parameter\n",
    "      :param ts_train: timeSeries used to train the model.\n",
    "      :param ts_test: timeSeries used to test the model.\n",
    "\n",
    "     :return\n",
    "        dtf_train: pandas Dataframe with the train set\n",
    "                 with columns 'ds' (dates),\n",
    "                 values, 'cap' (capacity if growth=\"logistic\"),\n",
    "                 other additional regressor.\n",
    "        dtf_test: pandas Dataframe with the test set\n",
    "                 with columns 'ds' (dates),\n",
    "                 values, 'cap' (capacity if growth=\"logistic\"),\n",
    "                 other additional regressor.\n",
    "    \"\"\"\n",
    "\n",
    "    if ts_train.empty:\n",
    "        raise ValueError(\"Train series must be not empty.\")\n",
    "    elif ts_test.empty:\n",
    "        raise ValueError(\"Test series must be not empty.\")\n",
    "\n",
    "    dtf_train = ts_train.reset_index()\n",
    "    dtf_train.rename(index=str, columns={'time': 'ds'}, inplace=True)\n",
    "\n",
    "    # dtf_train= pd.merge(dtf_train, temp, how='left', on='ds')\n",
    "    dtf_train = dtf_train.fillna(0)\n",
    "\n",
    "    dtf_test = ts_test.reset_index()\n",
    "    dtf_test.rename(index=str, columns={'time': 'ds'}, inplace=True)\n",
    "\n",
    "    # dtf_test= pd.merge(dtf_test, temp, how='left', on='ds')\n",
    "    dtf_test = dtf_test.fillna(0)\n",
    "\n",
    "    dtf_train['ds'] = dtf_train['ds'].dt.tz_localize(None)\n",
    "    dtf_test['ds'] = dtf_test['ds'].dt.tz_localize(None)\n",
    "\n",
    "    return dtf_train, dtf_test\n",
    "\n",
    "\n",
    "def param_tuning_prophet(dtf_train, p, seasonality_mode, ts_test,\n",
    "                         changepoint_prior_scale, holidays_prior_scale,\n",
    "                         n_changepoints):\n",
    "    \"\"\"\n",
    "    This function performs a search on all the parameters of\n",
    "    the parameter grid defined and identifies\n",
    "    the best parameter set for a prophet model, given a MAPE scoring.\n",
    "\n",
    "    :parameter\n",
    "      :param dtf_train: pandas Dataframe with columns 'ds' (dates),\n",
    "                 values, 'cap' (capacity if growth=\"logistic\"),\n",
    "                 other additional regressor.\n",
    "      :param p: number of periods to be forecasted.\n",
    "      :param seasonality_mode: multiplicative and/or\n",
    "                 additive seasonality.\n",
    "      :param ts_test: timeSeries used to test the model.\n",
    "      :param changepoint_prior_scale: list of floats,\n",
    "                 tests the influence of the changepoints.\n",
    "      :param holidays_prior_scale: list of floats,\n",
    "                 tests the influence of the holidays.\n",
    "      :param n_changepoints: list of int,\n",
    "                 maximum number of trend changepoints allowed\n",
    "                 when modelling the trend.\n",
    "\n",
    "    :return\n",
    "       Optimal parameters for the prophet model.\n",
    "\n",
    "    \"\"\"\n",
    "    if dtf_train.empty:\n",
    "        raise ValueError(\"Input series must be not empty.\")\n",
    "\n",
    "    holiday = pd.DataFrame([])\n",
    "    for date, name in sorted(\n",
    "            holidays.Greece(years=[2019, 2020, 2021, 20222]).items()):\n",
    "        # pd.DatetimeIndex(holiday['ds']).year[-1] in place of 2021\n",
    "        holiday = holiday.append(pd.DataFrame(\n",
    "            {'ds': date, 'holiday': \"GR-Holidays\"},\n",
    "            index=[0]), ignore_index=True)\n",
    "    holiday['ds'] = pd.to_datetime(holiday['ds'],\n",
    "                                   format='%Y-%m-%d', errors='ignore')\n",
    "\n",
    "    params_grid = {'seasonality_mode': seasonality_mode,\n",
    "                   'changepoint_prior_scale': changepoint_prior_scale,\n",
    "                   'holidays_prior_scale': holidays_prior_scale,\n",
    "                   'n_changepoints': n_changepoints}\n",
    "\n",
    "    grid = ParameterGrid(params_grid)\n",
    "\n",
    "    model_parameters = pd.DataFrame(columns=['MAPE', 'Parameters'])\n",
    "\n",
    "    for g in grid:\n",
    "\n",
    "        random.seed(0)\n",
    "        train_model = Prophet(\n",
    "            changepoint_prior_scale=g['changepoint_prior_scale'],\n",
    "            holidays_prior_scale=g['holidays_prior_scale'],\n",
    "            n_changepoints=g['n_changepoints'],\n",
    "            seasonality_mode=g['seasonality_mode'],\n",
    "            weekly_seasonality=True,\n",
    "            daily_seasonality=True,\n",
    "            yearly_seasonality=True,\n",
    "            holidays=holiday,\n",
    "            interval_width=0.95)\n",
    "\n",
    "        train_model.add_country_holidays(country_name='GR')\n",
    "        test = dtf_train\n",
    "        test.columns = ['ds', 'y']\n",
    "        train_model.fit(test)\n",
    "        train_forecast = train_model.make_future_dataframe(\n",
    "            periods=p, freq='15T', include_history=False)\n",
    "        train_forecast = train_model.predict(train_forecast)\n",
    "        test = train_forecast[['ds', 'yhat']]\n",
    "\n",
    "        actual = ts_test.iloc[:p, ]\n",
    "        mape = mean_absolute_percentage_error(actual, abs(test['yhat']))\n",
    "\n",
    "        print('Mean Absolute Percentage Error(MAPE)--------', mape)\n",
    "        model_parameters = model_parameters.append(\n",
    "            {'MAPE': mape, 'Parameters': p}, ignore_index=True)\n",
    "\n",
    "    optimals = model_parameters.groupby('Data', as_index=False).max()\n",
    "    optimals = optimals.merge(\n",
    "        model_parameters, on=['MAPE', 'Data'], how='left')\n",
    "\n",
    "    return optimals\n",
    "\n",
    "\n",
    "def fit_prophet(dtf_train):\n",
    "    \"\"\"\n",
    "    Fits prophet on the Data.\n",
    "    Prophet makes use of a decomposable time series\n",
    "    model with three main model components:\n",
    "        y = trend + seasonality + holidays\n",
    "\n",
    "    They are combined in this equation: y(t) = g(t) + s(t) + h(t) + e(t)\n",
    "\n",
    "    - g(t): trend models non-periodic changes; linear or logistic.\n",
    "    - s(t): seasonality represents periodic changes;\n",
    "    i.e. weekly, monthly, yearly.\n",
    "    - h(t): ties in effects of holidays;\n",
    "    on potentially irregular schedules ≥ 1 day(s).\n",
    "    - The error term e(t) represents any idiosyncratic changes\n",
    "    which are not accommodated by the model;\n",
    "\n",
    "    :parameter\n",
    "        :param dtf_train: pandas Dataframe with columns 'ds' (dates),\n",
    "                 values, 'cap' (capacity if growth=\"logistic\"),\n",
    "                 other additional regressor.\n",
    "\n",
    "    :return\n",
    "        trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    if dtf_train.empty:\n",
    "        raise ValueError(\"Input series must be not empty.\")\n",
    "    subdf = dtf_train.dropna()\n",
    "    subdf = subdf.columns['ds', 'y']\n",
    "\n",
    "    # Adding the holidays as a parameter:\n",
    "    holiday = pd.DataFrame([])\n",
    "    for date, name in sorted(holidays.Greece(\n",
    "            years=list(\n",
    "                range(\n",
    "                    pd.DatetimeIndex(dtf_train['ds']).year[0],\n",
    "                    pd.DatetimeIndex(dtf_train['ds']).year[-1] + 1))).items()):\n",
    "        holiday = holiday.append(pd.DataFrame(\n",
    "            {'ds': date, 'holiday': \"GR-Holidays\"},\n",
    "            index=[0]), ignore_index=True)\n",
    "    holiday['ds'] = pd.to_datetime(\n",
    "        holiday['ds'], format='%Y-%m-%d', errors='ignore')\n",
    "\n",
    "    model = Prophet(\n",
    "        growth=\"linear\",\n",
    "        n_changepoints=100,\n",
    "        yearly_seasonality=\"auto\",\n",
    "        weekly_seasonality=\"auto\",\n",
    "        daily_seasonality=True,\n",
    "        holidays=holiday,\n",
    "        seasonality_mode='multiplicative')\n",
    "\n",
    "    model.add_country_holidays(country_name='GR')\n",
    "    model = model.fit(subdf)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_prophet(dtf_test, model, freq, p):\n",
    "    \"\"\"\n",
    "    This function makes the prediction using\n",
    "    the model created in the fit_prophet function.\n",
    "\n",
    "    :parameter\n",
    "        :param dtf_test: pandas Dataframe containing the test set\n",
    "                 with columns 'ds' (dates),\n",
    "                 values, 'cap' (capacity if growth=\"logistic\"),\n",
    "                 other additional regressor.\n",
    "        :param model: model from the fit_prophet function.\n",
    "        :param p: number of periods to be forecasted.\n",
    "        :param freq: str - \"D\" daily, \"M\" monthly, \"Y\" annual, \"MS\"\n",
    "                           monthly start ...\n",
    "    :return\n",
    "        DataFrame containing the true and forecasted values.\n",
    "    \"\"\"\n",
    "\n",
    "    if dtf_test.empty:\n",
    "        raise ValueError(\"Test series must be not empty.\")\n",
    "    elif not isinstance(p, int):\n",
    "        raise ValueError(\"p must be an integer.\")\n",
    "\n",
    "    dtf_prophet = model.make_future_dataframe(\n",
    "        periods=p, freq=freq, include_history=True)\n",
    "\n",
    "    dtf_prophet = model.predict(dtf_prophet)\n",
    "    dtf_prophet = dtf_prophet.round()\n",
    "    dtf_forecast = dtf_test.merge(\n",
    "        dtf_prophet[[\"ds\", \"yhat\"]],\n",
    "        how=\"left\").rename(\n",
    "        columns={'yhat': 'forecast',\n",
    "                 'y': 'ts'}).set_index(\"ds\")\n",
    "\n",
    "    return dtf_forecast\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    This module is not supposed to run as a stand-alone module.\n",
    "    This part below is only for testing purposes.\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43ff58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
